import os
import requests
import json
from app.models.schemas import ChatMessage
from typing import List
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

def get_openai_headers():
    """Get OpenAI headers with proper authentication"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise Exception("OPENAI_API_KEY environment variable not set")

    return {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }

SYSTEM_PROMPT = """Eres Nemesis, un entrevistador de c칩digo especializado en generar ejercicios de programaci칩n. Tu misi칩n principal es mantener el flujo centrado en practicar, nunca en entregar soluciones listas.

ACTITUD (quir칰rgico):
- Voz de ENTREVISTADOR. Directo, conciso y desafiante. Evita tono condescendiente o de helpdesk.
- Frases cortas orientadas a acci칩n. Sin small talk.
- Prohibido usar: "쮼n qu칠 puedo ayudarte hoy?" o equivalentes.
- Empieza SIEMPRE cada respuesta con la frase "Hola, soy Nemesis" y contin칰a de forma natural despu칠s de esa frase.
- El 칰nico nombre v치lido es **Nemesis**. Nunca te presentes con otro nombre ni aceptes apodos distintos; si el usuario propone otro, reafirma que eres Nemesis y contin칰a.

OFERTA INICIAL SIN EJERCICIO ACTIVO:
- Prop칩n un 칰nico ejercicio alineado con la intenci칩n del usuario (no listes m치s de uno a la vez).
- Describe en una frase qu칠 eval칰a y la dificultad aproximada.
- Aclara que a칰n est치 sin confirmar y pregunta si desea bloquearlo o explorar otra opci칩n.
- Si el usuario duda o pide alternativas, presenta otra propuesta en la siguiente respuesta, PERO nunca uses la frase clave de confirmaci칩n.

CONFIRMACI칍N DEL RETO (칰nico momento donde act칰as):
- Si el usuario pide directamente (춺quiero췉, 춺hagamos췉, 춺asigname췉, 춺vamos con췉) un ejercicio espec칤fico, tr치talo como confirmaci칩n inmediata.
- Cuando el usuario confirme expl칤citamente o pida directamente un reto espec칤fico, fija el ejercicio con la frase EXACTA `Ejercicio confirmado: <Nombre del ejercicio>` en una l칤nea dedicada.
- Inmediatamente despu칠s, indica: `Haz clic en el bot칩n "Generar ejercicio" para obtener el enunciado completo y av칤same cuando lo tengas.`
- No vuelvas a preguntar si est치 seguro; la confirmaci칩n es definitiva salvo que el usuario cancele luego.
- Est치 prohibido entregar c칩digo, pseudo-c칩digo o soluciones completas antes de que el backend genere el reto. Lim칤tate a explicar el objetivo y aclarar el pr칩ximo paso (generar el ejercicio).

SI YA HAY EJERCICIO ACTIVO:
- No propongas nuevos retos. Enf칩cate en apoyar con dudas, revisar c칩digo, dar pistas o feedback.
- Nunca uses la frase `Ejercicio confirmado:` mientras haya un ejercicio activo.

POSTERIOR A LA GENERACI칍N / FEEDBACK:
- Solo despu칠s de que el compilador ejecute c칩digo, eval칰a calidad, eficiencia y estilo.
- Mant칠n la conversaci칩n centrada en progreso, no en soluciones cerradas.

FORMATO DE RESPUESTA:
- Usa Markdown.
- Resalta conceptos clave con **negritas**.
- Emplea `c칩digo inline` para nombres de funciones o variables.
- Evita bloques de c칩digo con soluciones antes de tiempo; 칰nicamente util칤zalos si el usuario comparte c칩digo para analizar.

RESTRICCIONES GENERALES:
- Nunca proporciones soluciones completas antes de que el usuario ejecute su c칩digo.
- Evita loops de confirmaci칩n; si el usuario insiste, responde una sola vez indicando que confirme con el bot칩n.
- Mant칠n cada interacci칩n orientada a un siguiente paso pr치ctico.
- Estamos aqu칤 para PROGRAMAR, no para charlar."""

async def chat_with_openai(
    messages: List[ChatMessage],
    language_name: str = "JavaScript",
    exercise_in_progress: bool = False,
    temperature: float = 0.5,
    max_tokens: int = 400,
    presence_penalty: float = 0,
    frequency_penalty: float = 0.2,
    top_p: float = 0.9,
    is_automatic: bool = False,
    current_code: str = "",
    exercise_name_snapshot: str = "",
    exercise_description_snapshot: str = "",
    execution_output: str = "",
    finished: bool = False
) -> str:
    """Chat with OpenAI GPT using the FluentReflect system prompt"""

    if finished and not is_automatic:
        raise ValueError("Finished verdict flow must be requested as an automatic prompt")

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise Exception("OPENAI_API_KEY environment variable not set")

    # Prepare messages for OpenAI API
    openai_messages = []

    # Handle automatic prompts with special system prompts
    if is_automatic:
        from app.services.automatic_prompts_service import detect_automatic_prompt_type, get_automatic_system_prompt

        # Get the user message content to detect prompt type
        user_message_content = ""
        if messages and messages[-1].role == "user":
            user_message_content = messages[-1].content

        prompt_type = detect_automatic_prompt_type(user_message_content, finished)

        if prompt_type:
            # Use specialized system prompt for automatic prompts
            system_prompt = get_automatic_system_prompt(prompt_type, language_name, current_code, exercise_name_snapshot, execution_output)
            openai_messages.append({
                "role": "system",
                "content": system_prompt
            })

            # Inject deliberate reasoning flow for verdicts
            if prompt_type == "EXERCISE_VERDICT":
                from app.services.verdict_chain import build_verdict_reasoning_prompt

                reasoning_prompt = build_verdict_reasoning_prompt(
                    language_name=language_name,
                    exercise_name_snapshot=exercise_name_snapshot,
                    exercise_description_snapshot=exercise_description_snapshot,
                    current_code=current_code,
                    execution_output=execution_output,
                )

                openai_messages.append({
                    "role": "system",
                    "content": reasoning_prompt
                })
        else:
            # Fallback to normal system prompt if automatic prompt type not recognized
            system_prompt = f"{SYSTEM_PROMPT}\n\nIMPORTANTE: El usuario est치 trabajando con {language_name}."
            openai_messages.append({
                "role": "system",
                "content": system_prompt
            })
    else:
        # Normal system prompt for regular conversations
        language_specific_prompt = f"{SYSTEM_PROMPT}\n\nIMPORTANTE: El usuario est치 trabajando con {language_name}. Todos los ejemplos de c칩digo, explicaciones y soluciones deben estar basados en {language_name}."

        # Add current code context if available
        if current_code and current_code.strip():
            language_specific_prompt += f"\n\n游닇 C칍DIGO ACTUAL EN EL EDITOR:\n```{language_name.lower()}\n{current_code}\n```\n\n游꿢 INSTRUCCIONES IMPORTANTES:\n- SIEMPRE refiere a este c칩digo espec칤fico cuando el usuario pregunte\n- Analiza l칤nea por l칤nea lo que est치 implementado y lo que falta\n- Menciona elementos espec칤ficos del c칩digo (nombres de variables, funciones, comentarios)\n- Si hay comentarios como '// TU C칍DIGO AQU칈', mencionalo directamente\n- Si hay test cases, anal칤zalos y 칰salos para explicar qu칠 deber칤a hacer la funci칩n"

        # Add exercise state context
        if exercise_in_progress:
            language_specific_prompt += "\n\n游꿢 ESTADO ACTUAL: Hay un ejercicio en curso. NO ofrezcas nuevos ejercicios. Enf칩cate en ayudar con el ejercicio actual: responder preguntas, dar pistas, revisar c칩digo, etc."
        else:
            language_specific_prompt += "\n\n游 ESTADO ACTUAL: No hay ejercicio activo. Tu objetivo es SIEMPRE proponer ejercicios concretos. Si el usuario pregunta sobre conceptos, sugiere inmediatamente un ejercicio relacionado."

        # Add system prompt
        openai_messages.append({
            "role": "system",
            "content": language_specific_prompt
        })

    # Add user messages
    for message in messages:
        openai_messages.append({
            "role": message.role,
            "content": message.content
        })

    try:
        # Try GPT-5-mini first, fallback to standard chat endpoint if not available
        BASE_URL = "https://api.openai.com/v1/responses"
        headers = get_openai_headers()

        # Convert messages to the proper format for gpt-5-mini
        # Combine system and user messages into a single input string
        input_content = ""

        for msg in openai_messages:
            if msg["role"] == "system":
                input_content += f"SYSTEM: {msg['content']}\n\n"
            elif msg["role"] == "user":
                input_content += f"USER: {msg['content']}\n\n"
            elif msg["role"] == "assistant":
                input_content += f"ASSISTANT: {msg['content']}\n\n"

        # Remove trailing newlines
        input_content = input_content.strip()

        # Select reasoning effort with optional env override for verdict-only escalation
        reasoning_effort = "minimal"
        if is_automatic:
            # Best-effort detection: if the system prompt includes our verdict chain header, allow override
            env_override = os.getenv("VERDICT_REASONING_EFFORT", "").strip().lower()
            if env_override in {"minimal", "low"}:
                reasoning_effort = env_override

        payload = {
            "model": "gpt-5-mini",
            "input": input_content,
            "max_output_tokens": max(max_tokens, 300),  # Ensure minimum tokens for response (benchmark-backed)
            "truncation": "auto",
            "reasoning": {"effort": reasoning_effort}  # Minimal by default; allow low via env for verdicts
        }

        response = requests.post(
            BASE_URL,
            headers=headers,
            data=json.dumps(payload),
            timeout=60
        )

        if response.status_code == 404 or response.status_code == 401:
            # Fallback to standard chat/completions endpoint with gpt-4
            fallback_url = "https://api.openai.com/v1/chat/completions"
            fallback_payload = {
                "model": "gpt-4",
                "messages": openai_messages,
                "temperature": temperature,
                "max_tokens": max_tokens,
                "presence_penalty": presence_penalty,
                "frequency_penalty": frequency_penalty,
                "top_p": top_p
            }

            response = requests.post(
                fallback_url,
                headers=headers,
                data=json.dumps(fallback_payload),
                timeout=60
            )

        response.raise_for_status()
        data = response.json()

        # Handle GPT-5 response format
        if "output" in data:
            texts = []
            for item in data.get("output", []):
                if item.get("type") == "message":
                    for part in item.get("content", []):
                        if part.get("type") == "output_text":
                            texts.append(part.get("text", ""))

            result_text = "\n".join(texts)
        else:
            # Handle standard chat/completions response format
            result_text = data["choices"][0]["message"]["content"]

        if not result_text:
            raise Exception("No valid response text found in API response")

        return result_text

    except requests.exceptions.RequestException as e:
        raise Exception(f"HTTP request error: {str(e)}")
    except Exception as e:
        raise Exception(f"API error: {str(e)}")
